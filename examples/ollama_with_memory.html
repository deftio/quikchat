<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"
        type="image/gif">

    <title>YackBox Demo with local Ollama</title>
    <!-- Include Bootstrap CSS file -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <!-- Include Yackbox Chat CSS file -->
    <link rel="stylesheet" href="../../dist/quikchat.css">

    <!-- Include Yackbox Chat JavaScript file -->
    <script src="../../dist/quikchat.umd.min.js"></script>

    <script src="./ollama_adapters.js"></script>
    <style>
        html,
        body {
            width: 100%;
            height: 100%;
        }

        .chat-container {
            height: 70vh;
            width: 100%;
        }
    </style>

</head>

<body>


    <div class="container">
        <br>
        <h2 class="">Ollama quikchat Demo with Conversational Memory</h2>
        <p>This example demonstrates how to use quikchat with a local LLM using Ollama where quikchat provides the
            chat history to Ollama provides the llm model.  This allows the chat to "remember" what is being discussed.</p>
        <br>
        <div class="row">
            <div class="col-10">
                <div class="chat-container" id="chat-container"></div>
            </div>
        </div>
    </div>

    <script>

        // set up chat instance
        const streamingChat = new quikchat('#chat-container', {
                theme: 'quikchat-theme-light',
                onSend: getOllamaStreamingCallback,
                titleArea: { title: "Memory Chat", "show": true, "align": "left" },
            });
        //streamingChat.setDefaultUserName("Me", "left");  // this is the user's name
        streamingChat.messageAddNew("How can I help? ", "bot", "left", "system");


        // this calls the Ollama Streaming API with token streaming
        function getOllamaStreamingCallback(chatInstance, userInput) {
            var fetchedData = [];
            let start = true;
            chatInstance.messageAddNew(userInput, "user", "right"); // echos the user input to the chat
            return fetch('http://localhost:11434/api/chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: "llama3.1",
                    messages: chatInstance.historyGet(), // passes the chat history to the model
                    stream: true
                })
            })
                .then(response => {
                    if (!response.ok) {
                        throw new Error(`HTTP error! Status: ${response.status}`);
                    }
                    return response.body.getReader();
                })
                .then(reader => {
                    let partialData = '';
                    let id;

                    // Read and process the NDJSON response
                    return reader.read().then(function processResult(result) {
                        if (result.done) {
                            return;
                        }
                        let x = new TextDecoder().decode(result.value, { stream: true });
                        
                        let y = JSON.parse(x);
                        let content = y.message.content;//.message.content;
                        if (start) {
                            id = chatInstance.messageAddNew(content, "bot", "left"); // start a new chat message
                            start = false;
                        }
                        else {
                            chatInstance.messageAppendContent(id, content); // append new content to message
                        }

                        return reader.read().then(processResult);
                    });
                })
                .then(() => {
                    // At this point, fetchedData contains all the parsed JSON objects
                    //console.log(fetchedData); // use this to see the entire response
                })
                .catch(error => {
                    console.error('Fetch error:', error);
                });
        }


    </script>
</body>

</html>